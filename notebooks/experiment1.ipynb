{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN Experiment 1: Interactive Training with Visualizations\n",
    "\n",
    "This notebook implements the CycleGAN training loop interactively, allowing for data visualization, train/val/test splitting, and real-time monitoring of generated images.\n",
    "\n",
    "**Features:**\n",
    "- Saves checkpoints to Google Drive every epoch.\n",
    "- **Auto-Resuming:** Checks for existing checkpoints in Drive and resumes training if found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub Configuration & Setup\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Please double-check this path matches where you cloned the repo in your Drive\n",
    "REPO_PATH = '/content/drive/MyDrive/Kaggle_GANS_I-m-Something-of-a-Painter-Myself_Competition'\n",
    "\n",
    "try:\n",
    "    # 1. Change to the repository directory\n",
    "    if os.path.exists(REPO_PATH):\n",
    "        %cd \"$REPO_PATH\"\n",
    "        print(f\"Changed directory to {REPO_PATH}\")\n",
    "    else:\n",
    "        print(f\"Warning: Could not find repository at {REPO_PATH}.\")\n",
    "        print(\"Please update 'REPO_PATH' variable to point to your cloned repository folder.\")\n",
    "        # Attempting to list MyDrive to help user find the folder\n",
    "        print(\"Listing folders in MyDrive to help identify path:\")\n",
    "        !ls -d /content/drive/MyDrive/*/\n",
    "\n",
    "    # 2. Configure Git\n",
    "    user_name = \"konstantine25b\"\n",
    "    mail = \"konstantine25b@gmail.com\"\n",
    "    repo_url = \"https://github.com/konstantine25b/Kaggle_GANS_I-m-Something-of-a-Painter-Myself_Competition.git\"\n",
    "\n",
    "    !git config --global user.name \"{user_name}\"\n",
    "    !git config --global user.email \"{mail}\"\n",
    "    \n",
    "    # 3. Set Remote URL\n",
    "    # Only run this if we are in a git repo\n",
    "    if os.path.isdir(\".git\"):\n",
    "        # Uncomment the next line if you need to set the remote URL with a token manually\n",
    "        # !git remote set-url origin \"{repo_url}\"\n",
    "        print(\"Git configured successfully.\")\n",
    "    else:\n",
    "        print(\"Current directory is not a git repository. Skipping remote setup.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error setting up GitHub: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Add src to path so we can import modules\n",
    "sys.path.append('src')\n",
    "\n",
    "from models.generator.resnet_gan import ResNetGenerator\n",
    "from models.discriminator.patch_gan import PatchDiscriminator\n",
    "from utils.dataset import ImageDataset, get_transforms\n",
    "from utils.helpers import ReplayBuffer, weights_init_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Splitting\n",
    "\n",
    "We will load the file paths and split them into Train, Validation, and Test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# Note: Adjust these paths if your data is located elsewhere (e.g., in Drive or downloaded)\n",
    "MONET_PATH = 'data/monet_jpg'\n",
    "PHOTO_PATH = 'data/photo_jpg'\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/MonetGAN_Checkpoints_Exp1'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "N_EPOCHS = 5\n",
    "LR = 0.0002\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths\n",
    "monet_files = sorted(glob.glob(os.path.join(MONET_PATH, \"*.*\")))\n",
    "photo_files = sorted(glob.glob(os.path.join(PHOTO_PATH, \"*.*\")))\n",
    "\n",
    "print(f\"Total Monet images: {len(monet_files)}\")\n",
    "print(f\"Total Photo images: {len(photo_files)}\")\n",
    "\n",
    "# Shuffle files for splitting\n",
    "random.seed(42)\n",
    "random.shuffle(monet_files)\n",
    "random.shuffle(photo_files)\n",
    "\n",
    "# Split function\n",
    "def split_data(files, train_frac=0.8, val_frac=0.1):\n",
    "    n = len(files)\n",
    "    train_end = int(n * train_frac)\n",
    "    val_end = int(n * (train_frac + val_frac))\n",
    "    \n",
    "    train = files[:train_end]\n",
    "    val = files[train_end:val_end]\n",
    "    test = files[val_end:]\n",
    "    return train, val, test\n",
    "\n",
    "monet_train, monet_val, monet_test = split_data(monet_files)\n",
    "photo_train, photo_val, photo_test = split_data(photo_files)\n",
    "\n",
    "print(f\"Monet Splits - Train: {len(monet_train)}, Val: {len(monet_val)}, Test: {len(monet_test)}\")\n",
    "print(f\"Photo Splits - Train: {len(photo_train)}, Val: {len(photo_val)}, Test: {len(photo_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datasets and DataLoaders\n",
    "transforms_ = get_transforms()\n",
    "\n",
    "train_dataset = ImageDataset(monet_train, photo_train, transform=transforms_)\n",
    "val_dataset = ImageDataset(monet_val, photo_val, transform=transforms_)\n",
    "test_dataset = ImageDataset(monet_test, photo_test, transform=transforms_)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Data\n",
    "\n",
    "Let's look at some samples from our training loader to verify the data is loading correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor):\n",
    "    \"\"\"Reverses the normalization applied in transforms.\"\"\"\n",
    "    return tensor * 0.5 + 0.5\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "real_monet = batch['monet']\n",
    "real_photo = batch['photo']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(denormalize(real_monet[0]).permute(1, 2, 0).cpu().numpy())\n",
    "plt.title(\"Real Monet\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(denormalize(real_photo[0]).permute(1, 2, 0).cpu().numpy())\n",
    "plt.title(\"Real Photo\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Initialization & Resume Logic\n",
    "\n",
    "We initialize the models and check if there are any saved checkpoints in Google Drive to resume from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Generator and Discriminator\n",
    "G_Monet = ResNetGenerator().to(DEVICE)\n",
    "G_Photo = ResNetGenerator().to(DEVICE)\n",
    "D_Monet = PatchDiscriminator().to(DEVICE)\n",
    "D_Photo = PatchDiscriminator().to(DEVICE)\n",
    "\n",
    "# Apply weights\n",
    "G_Monet.apply(weights_init_normal)\n",
    "G_Photo.apply(weights_init_normal)\n",
    "D_Monet.apply(weights_init_normal)\n",
    "D_Photo.apply(weights_init_normal)\n",
    "\n",
    "# Loss functions\n",
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(\n",
    "    itertools.chain(G_Monet.parameters(), G_Photo.parameters()),\n",
    "    lr=LR, betas=(0.5, 0.999)\n",
    ")\n",
    "optimizer_D_Monet = torch.optim.Adam(D_Monet.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "optimizer_D_Photo = torch.optim.Adam(D_Photo.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "\n",
    "# Learning Rate Schedulers\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_G, lr_lambda=lambda epoch: 1.0 - max(0, epoch - 25) / float(50 - 25 + 1)\n",
    ")\n",
    "lr_scheduler_D_Monet = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_D_Monet, lr_lambda=lambda epoch: 1.0 - max(0, epoch - 25) / float(50 - 25 + 1)\n",
    ")\n",
    "lr_scheduler_D_Photo = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_D_Photo, lr_lambda=lambda epoch: 1.0 - max(0, epoch - 25) / float(50 - 25 + 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RESUME LOGIC ---\n",
    "def find_latest_checkpoint(checkpoint_dir):\n",
    "    files = glob.glob(os.path.join(checkpoint_dir, \"G_Monet_epoch_*.pth\"))\n",
    "    if not files:\n",
    "        return 0\n",
    "    epochs = [int(re.search(r'epoch_(\\d+).pth', f).group(1)) for f in files]\n",
    "    return max(epochs)\n",
    "\n",
    "start_epoch = find_latest_checkpoint(CHECKPOINT_DIR)\n",
    "\n",
    "if start_epoch > 0:\n",
    "    print(f\"Found checkpoint! Resuming from epoch {start_epoch}...\")\n",
    "    G_Monet.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, f'G_Monet_epoch_{start_epoch}.pth'), map_location=DEVICE))\n",
    "    G_Photo.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, f'G_Photo_epoch_{start_epoch}.pth'), map_location=DEVICE))\n",
    "    D_Monet.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, f'D_Monet_epoch_{start_epoch}.pth'), map_location=DEVICE))\n",
    "    D_Photo.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, f'D_Photo_epoch_{start_epoch}.pth'), map_location=DEVICE))\n",
    "    \n",
    "    # Fast forward schedulers\n",
    "    for _ in range(start_epoch):\n",
    "        lr_scheduler_G.step()\n",
    "        lr_scheduler_D_Monet.step()\n",
    "        lr_scheduler_D_Photo.step()\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop with Visualizations\n",
    "\n",
    "We will train for the remaining epochs, visualizing the output on a fixed sample from the validation set every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a fixed sample for visualization\n",
    "val_batch = next(iter(val_loader))\n",
    "fixed_monet = val_batch['monet'].to(DEVICE)\n",
    "fixed_photo = val_batch['photo'].to(DEVICE)\n",
    "\n",
    "fake_monet_buffer = ReplayBuffer()\n",
    "fake_photo_buffer = ReplayBuffer()\n",
    "\n",
    "def show_generated_images(real_p, fake_m, real_m, fake_p):\n",
    "    \"\"\"Helper to display images.\"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    images = [real_p, fake_m, real_m, fake_p]\n",
    "    titles = ['Real Photo', 'Generated Monet', 'Real Monet', 'Generated Photo']\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(denormalize(img[0]).permute(1, 2, 0).cpu().detach().numpy())\n",
    "        plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(f\"Starting training from epoch {start_epoch} to {N_EPOCHS}...\")\n",
    "\n",
    "for epoch in range(start_epoch, N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # --- Training ---\n",
    "    G_Monet.train(); G_Photo.train(); D_Monet.train(); D_Photo.train()\n",
    "    \n",
    "    epoch_loss_G = 0.0\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{N_EPOCHS}\")):\n",
    "        real_monet = batch['monet'].to(DEVICE)\n",
    "        real_photo = batch['photo'].to(DEVICE)\n",
    "        \n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        loss_id_A = criterion_identity(G_Monet(real_monet), real_monet)\n",
    "        loss_id_B = criterion_identity(G_Photo(real_photo), real_photo)\n",
    "        loss_identity = (loss_id_A + loss_id_B) / 2\n",
    "\n",
    "        # GAN loss\n",
    "        fake_monet = G_Monet(real_photo)\n",
    "        loss_GAN_AB = criterion_GAN(D_Monet(fake_monet), torch.ones_like(D_Monet(fake_monet)))\n",
    "\n",
    "        fake_photo = G_Photo(real_monet)\n",
    "        loss_GAN_BA = criterion_GAN(D_Photo(fake_photo), torch.ones_like(D_Photo(fake_photo)))\n",
    "\n",
    "        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
    "\n",
    "        # Cycle loss\n",
    "        rec_photo = G_Photo(fake_monet)\n",
    "        loss_cycle_A = criterion_cycle(rec_photo, real_photo)\n",
    "\n",
    "        rec_monet = G_Monet(fake_photo)\n",
    "        loss_cycle_B = criterion_cycle(rec_monet, real_monet)\n",
    "\n",
    "        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = loss_GAN + (10.0 * loss_cycle) + (5.0 * loss_identity)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        epoch_loss_G += loss_G.item()\n",
    "\n",
    "        # -----------------------\n",
    "        #  Train Discriminator A\n",
    "        # -----------------------\n",
    "        optimizer_D_Monet.zero_grad()\n",
    "        loss_real = criterion_GAN(D_Monet(real_monet), torch.ones_like(D_Monet(real_monet)))\n",
    "        fake_monet_ = fake_monet_buffer.push_and_pop(fake_monet)\n",
    "        loss_fake = criterion_GAN(D_Monet(fake_monet_.detach()), torch.zeros_like(D_Monet(fake_monet_)))\n",
    "        loss_D_Monet = (loss_real + loss_fake) / 2\n",
    "        loss_D_Monet.backward()\n",
    "        optimizer_D_Monet.step()\n",
    "\n",
    "        # -----------------------\n",
    "        #  Train Discriminator B\n",
    "        # -----------------------\n",
    "        optimizer_D_Photo.zero_grad()\n",
    "        loss_real = criterion_GAN(D_Photo(real_photo), torch.ones_like(D_Photo(real_photo)))\n",
    "        fake_photo_ = fake_photo_buffer.push_and_pop(fake_photo)\n",
    "        loss_fake = criterion_GAN(D_Photo(fake_photo_.detach()), torch.zeros_like(D_Photo(fake_photo_)))\n",
    "        loss_D_Photo = (loss_real + loss_fake) / 2\n",
    "        loss_D_Photo.backward()\n",
    "        optimizer_D_Photo.step()\n",
    "    \n",
    "    # --- Update Learning Rate ---\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_Monet.step()\n",
    "    lr_scheduler_D_Photo.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} finished. Avg Generator Loss: {epoch_loss_G / len(train_loader):.4f}\")\n",
    "    \n",
    "    # --- Validation / Visualization ---\n",
    "    if (epoch + 1) % 1 == 0: # Visualize every epoch\n",
    "        G_Monet.eval()\n",
    "        G_Photo.eval()\n",
    "        with torch.no_grad():\n",
    "            fake_monet_vis = G_Monet(fixed_photo)\n",
    "            fake_photo_vis = G_Photo(fixed_monet)\n",
    "            show_generated_images(fixed_photo, fake_monet_vis, fixed_monet, fake_photo_vis)\n",
    "            \n",
    "    # --- Save Checkpoints ---\n",
    "    # Save EVERY epoch now\n",
    "    torch.save(G_Monet.state_dict(), os.path.join(CHECKPOINT_DIR, f'G_Monet_epoch_{epoch+1}.pth'))\n",
    "    torch.save(G_Photo.state_dict(), os.path.join(CHECKPOINT_DIR, f'G_Photo_epoch_{epoch+1}.pth'))\n",
    "    torch.save(D_Monet.state_dict(), os.path.join(CHECKPOINT_DIR, f'D_Monet_epoch_{epoch+1}.pth'))\n",
    "    torch.save(D_Photo.state_dict(), os.path.join(CHECKPOINT_DIR, f'D_Photo_epoch_{epoch+1}.pth'))\n",
    "    print(f\"Saved checkpoint for epoch {epoch+1} to {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing\n",
    "\n",
    "Finally, let's run the generator on the test set and see some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_Monet.eval()\n",
    "\n",
    "test_iter = iter(test_loader)\n",
    "\n",
    "# Show first 5 test images\n",
    "for i in range(5):\n",
    "    try:\n",
    "        batch = next(test_iter)\n",
    "        real_photo = batch['photo'].to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            fake_monet = G_Monet(real_photo)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(denormalize(real_photo[0]).permute(1, 2, 0).cpu().numpy())\n",
    "        plt.title(\"Real Photo (Test)\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(denormalize(fake_monet[0]).permute(1, 2, 0).cpu().numpy())\n",
    "        plt.title(\"Generated Monet (Test)\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except StopIteration:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
