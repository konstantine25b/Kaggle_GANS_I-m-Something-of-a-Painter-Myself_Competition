{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN Experiment 1: Interactive Training with Visualizations\n",
    "\n",
    "This notebook implements the CycleGAN training loop interactively, allowing for data visualization, train/val/test splitting, and real-time monitoring of generated images.\n",
    "\n",
    "**Features:**\n",
    "- Saves checkpoints to Google Drive every epoch.\n",
    "- **Auto-Resuming:** Checks for existing checkpoints in Drive and resumes training if found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub Configuration & Setup\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Please double-check this path matches where you cloned the repo in your Drive\n",
    "REPO_PATH = '/content/drive/MyDrive/Kaggle_GANS_I-m-Something-of-a-Painter-Myself_Competition'\n",
    "\n",
    "try:\n",
    "    # 1. Change to the repository directory\n",
    "    if os.path.exists(REPO_PATH):\n",
    "        %cd \"$REPO_PATH\"\n",
    "        print(f\"Changed directory to {REPO_PATH}\")\n",
    "    else:\n",
    "        print(f\"Warning: Could not find repository at {REPO_PATH}.\")\n",
    "        print(\"Please update 'REPO_PATH' variable to point to your cloned repository folder.\")\n",
    "        # Attempting to list MyDrive to help user find the folder\n",
    "        print(\"Listing folders in MyDrive to help identify path:\")\n",
    "        !ls -d /content/drive/MyDrive/*/\n",
    "\n",
    "    # 2. Configure Git\n",
    "    user_name = \"konstantine25b\"\n",
    "    mail = \"konstantine25b@gmail.com\"\n",
    "    \n",
    "    # --- IMPORTANT: PASTE YOUR TOKEN BELOW ---\n",
    "    # Replace 'YOUR_TOKEN_HERE' with your actual GitHub token (starting with github_pat_...)\n",
    "    my_token = \"YOUR_TOKEN_HERE\"\n",
    "    \n",
    "    if my_token == \"YOUR_TOKEN_HERE\":\n",
    "        print(\"\u26a0\ufe0f PLEASE UPDATE 'my_token' in the code cell with your actual GitHub token to enable pushing.\")\n",
    "    \n",
    "    repo_url = f\"https://{my_token}@github.com/konstantine25b/Kaggle_GANS_I-m-Something-of-a-Painter-Myself_Competition.git\"\n",
    "\n",
    "    !git config --global user.name \"{user_name}\"\n",
    "    !git config --global user.email \"{mail}\"\n",
    "    \n",
    "    # 3. Set Remote URL\n",
    "    # Only run this if we are in a git repo and token is set\n",
    "    if os.path.isdir(\".git\") and my_token != \"YOUR_TOKEN_HERE\":\n",
    "        !git remote set-url origin \"{repo_url}\"\n",
    "        print(\"Git configured successfully for pushing.\")\n",
    "    else:\n",
    "        print(\"Skipping remote setup (either not a git repo or token not set).\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error setting up GitHub: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install -r requirements.txt",
    "\n!pip install wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Add src to path so we can import modules\n",
    "sys.path.append('src')\n",
    "\n",
    "from models.generator.resnet_gan import ResNetGenerator\n",
    "from models.discriminator.patch_gan import PatchDiscriminator\n",
    "from utils.dataset import ImageDataset, get_transforms\n",
    "from utils.helpers import ReplayBuffer, weights_init_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to WandB\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Splitting\n",
    "\n",
    "We will load the file paths and split them into Train, Validation, and Test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "# Note: Adjust these paths if your data is located elsewhere (e.g., in Drive or downloaded)\n",
    "MONET_PATH = 'data/monet_jpg'\n",
    "PHOTO_PATH = 'data/photo_jpg'\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/MonetGAN_Checkpoints_Exp1'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "N_EPOCHS = 30\n",
    "LR = 0.0002\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- QUICK TEST SETTING ---\n",
    "# Set to True for a quick sanity check (30 images), False for full training\n",
    "QUICK_TEST = True \n",
    "\n",
    "# Initialize WandB\n",
    "wandb.init(\n",
    "    project=\"Monet_GAn\",\n",
    "    entity=\"konstantine25b-free-university-of-tbilisi-\",\n",
    "    config={\n",
    "        \"epochs\": N_EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LR,\n",
    "        \"architecture\": \"CycleGAN-ResNet\",\n",
    "        \"dataset\": \"Monet2Photo\",\n",
    "        \"quick_test\": QUICK_TEST\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WandB Report Information\n",
    "\n",
    "**Project:** Monet GAN  \n",
    "**Architecture:** CycleGAN with ResNet Generator (9 blocks) and PatchGAN Discriminator (70x70).  \n",
    "**Loss Functions:**  \n",
    "- Adversarial Loss (MSE)  \n",
    "- Cycle Consistency Loss (L1)  \n",
    "- Identity Loss (L1)  \n",
    "\n",
    "**Experiment Goal:** Translate photos to Monet-style paintings while preserving content structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths\n",
    "monet_files = sorted(glob.glob(os.path.join(MONET_PATH, \"*.*\")))\n",
    "photo_files = sorted(glob.glob(os.path.join(PHOTO_PATH, \"*.*\")))\n",
    "\n",
    "if QUICK_TEST:\n",
    "    print(\"\u26a0\ufe0f QUICK TEST MODE ENABLED: Using only 30 images to verify code flow.\")\n",
    "    monet_files = monet_files[:30]\n",
    "    photo_files = photo_files[:30]\n",
    "\n",
    "print(f\"Total Monet images: {len(monet_files)}\")\n",
    "print(f\"Total Photo images: {len(photo_files)}\")\n",
    "\n",
    "# Shuffle files for splitting\n",
    "random.seed(42)\n",
    "random.shuffle(monet_files)\n",
    "random.shuffle(photo_files)\n",
    "\n",
    "# Modified split function: maximize training data\n",
    "def split_data(files, is_monet=False):\n",
    "    # We need at least 1 image for validation to support the visualization code\n",
    "    n_val = 1\n",
    "    \n",
    "    if is_monet:\n",
    "        # For Monet: \n",
    "        # - Train: All except 1\n",
    "        # - Val: 1 image (for viz)\n",
    "        # - Test: 0 images (we don't generate FROM Monet)\n",
    "        val = files[:n_val]\n",
    "        train = files[n_val:]\n",
    "        test = []\n",
    "    else:\n",
    "        # For Photos:\n",
    "        # - Test: 30 images (or 1 if quick test)\n",
    "        # - Val: 1 image\n",
    "        # - Train: Everything else\n",
    "        n_test = 1 if QUICK_TEST else 30\n",
    "        val = files[:n_val]\n",
    "        test = files[n_val:n_val+n_test]\n",
    "        train = files[n_val+n_test:]\n",
    "        \n",
    "    return train, val, test\n",
    "\n",
    "# Use almost all Monet for training (just 1 for val viz)\n",
    "monet_train, monet_val, monet_test = split_data(monet_files, is_monet=True)\n",
    "photo_train, photo_val, photo_test = split_data(photo_files, is_monet=False)\n",
    "\n",
    "print(f\"Monet Splits - Train: {len(monet_train)}, Val: {len(monet_val)}, Test: {len(monet_test)}\")\n",
    "print(f\"Photo Splits - Train: {len(photo_train)}, Val: {len(photo_val)}, Test: {len(photo_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datasets and DataLoaders\n",
    "transforms_ = get_transforms()\n",
    "\n",
    "train_dataset = ImageDataset(monet_train, photo_train, transform=transforms_)\n",
    "val_dataset = ImageDataset(monet_val, photo_val, transform=transforms_)\n",
    "test_dataset = ImageDataset(monet_test, photo_test, transform=transforms_)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Data\n",
    "\n",
    "Let's look at some samples from our training loader to verify the data is loading correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor):\n",
    "    \"\"\"Reverses the normalization applied in transforms.\"\"\"\n",
    "    return tensor * 0.5 + 0.5\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "real_monet = batch['monet']\n",
    "real_photo = batch['photo']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(denormalize(real_monet[0]).permute(1, 2, 0).cpu().numpy())\n",
    "plt.title(\"Real Monet\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(denormalize(real_photo[0]).permute(1, 2, 0).cpu().numpy())\n",
    "plt.title(\"Real Photo\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Initialization & Resume Logic\n",
    "\n",
    "We initialize the models and check if there are any saved checkpoints in Google Drive to resume from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Generator and Discriminator\n",
    "G_Monet = ResNetGenerator().to(DEVICE)\n",
    "G_Photo = ResNetGenerator().to(DEVICE)\n",
    "D_Monet = PatchDiscriminator().to(DEVICE)\n",
    "D_Photo = PatchDiscriminator().to(DEVICE)\n",
    "\n",
    "# Apply weights\n",
    "G_Monet.apply(weights_init_normal)\n",
    "G_Photo.apply(weights_init_normal)\n",
    "D_Monet.apply(weights_init_normal)\n",
    "D_Photo.apply(weights_init_normal)\n",
    "\n",
    "# Loss functions\n",
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(\n",
    "    itertools.chain(G_Monet.parameters(), G_Photo.parameters()),\n",
    "    lr=LR, betas=(0.5, 0.999)\n",
    ")\n",
    "optimizer_D_Monet = torch.optim.Adam(D_Monet.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "optimizer_D_Photo = torch.optim.Adam(D_Photo.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "\n",
    "# Learning Rate Schedulers\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_G, lr_lambda=lambda epoch: 1.0 - max(0, epoch - 25) / float(50 - 25 + 1)\n",
    ")\n",
    "lr_scheduler_D_Monet = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_D_Monet, lr_lambda=lambda epoch: 1.0 - max(0, epoch - 25) / float(50 - 25 + 1)\n",
    ")\n",
    "lr_scheduler_D_Photo = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_D_Photo, lr_lambda=lambda epoch: 1.0 - max(0, epoch - 25) / float(50 - 25 + 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RESUME LOGIC ---\n",
    "def find_latest_checkpoint(checkpoint_dir):\n",
    "    files = glob.glob(os.path.join(checkpoint_dir, \"G_Monet_epoch_*.pth\"))\n",
    "    if not files:\n",
    "        return 0\n",
    "    epochs = [int(re.search(r'epoch_(\\d+).pth', f).group(1)) for f in files]\n",
    "    return max(epochs)\n",
    "\n",
    "start_epoch = find_latest_checkpoint(CHECKPOINT_DIR)\n",
    "\n",
    "if start_epoch > 0:\n",
    "    print(f\"Found checkpoint! Resuming from epoch {start_epoch}...\")\n",
    "    G_Monet.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, f'G_Monet_epoch_{start_epoch}.pth'), map_location=DEVICE))\n",
    "    G_Photo.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, f'G_Photo_epoch_{start_epoch}.pth'), map_location=DEVICE))\n",
    "    D_Monet.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, f'D_Monet_epoch_{start_epoch}.pth'), map_location=DEVICE))\n",
    "    D_Photo.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, f'D_Photo_epoch_{start_epoch}.pth'), map_location=DEVICE))\n",
    "    \n",
    "    # Fast forward schedulers\n",
    "    for _ in range(start_epoch):\n",
    "        lr_scheduler_G.step()\n",
    "        lr_scheduler_D_Monet.step()\n",
    "        lr_scheduler_D_Photo.step()\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop with Visualizations\n",
    "\n",
    "We will train for the remaining epochs, visualizing the output on a fixed sample from the validation set every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a fixed sample for visualization\n",
    "val_batch = next(iter(val_loader))\n",
    "fixed_monet = val_batch['monet'].to(DEVICE)\n",
    "fixed_photo = val_batch['photo'].to(DEVICE)\n",
    "\n",
    "fake_monet_buffer = ReplayBuffer()\n",
    "fake_photo_buffer = ReplayBuffer()\n",
    "\n",
    "def show_generated_images(real_p, fake_m, real_m, fake_p):\n",
    "    \"\"\"Helper to display images.\"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    images = [real_p, fake_m, real_m, fake_p]\n",
    "    titles = ['Real Photo', 'Generated Monet', 'Real Monet', 'Generated Photo']\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(denormalize(img[0]).permute(1, 2, 0).cpu().detach().numpy())\n",
    "        plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(f\"Starting training from epoch {start_epoch} to {N_EPOCHS}...\")\n",
    "\n",
    "for epoch in range(start_epoch, N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # --- Training ---\n",
    "    G_Monet.train(); G_Photo.train(); D_Monet.train(); D_Photo.train()\n",
    "    \n",
    "    epoch_loss_G = 0.0\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{N_EPOCHS}\")):\n",
    "        real_monet = batch['monet'].to(DEVICE)\n",
    "        real_photo = batch['photo'].to(DEVICE)\n",
    "        \n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        loss_id_A = criterion_identity(G_Monet(real_monet), real_monet)\n",
    "        loss_id_B = criterion_identity(G_Photo(real_photo), real_photo)\n",
    "        loss_identity = (loss_id_A + loss_id_B) / 2\n",
    "\n",
    "        # GAN loss\n",
    "        fake_monet = G_Monet(real_photo)\n",
    "        loss_GAN_AB = criterion_GAN(D_Monet(fake_monet), torch.ones_like(D_Monet(fake_monet)))\n",
    "\n",
    "        fake_photo = G_Photo(real_monet)\n",
    "        loss_GAN_BA = criterion_GAN(D_Photo(fake_photo), torch.ones_like(D_Photo(fake_photo)))\n",
    "\n",
    "        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
    "\n",
    "        # Cycle loss\n",
    "        rec_photo = G_Photo(fake_monet)\n",
    "        loss_cycle_A = criterion_cycle(rec_photo, real_photo)\n",
    "\n",
    "        rec_monet = G_Monet(fake_photo)\n",
    "        loss_cycle_B = criterion_cycle(rec_monet, real_monet)\n",
    "\n",
    "        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = loss_GAN + (10.0 * loss_cycle) + (5.0 * loss_identity)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        epoch_loss_G += loss_G.item()\n",
    "\n        # --- WandB Log Batch ---\n        wandb.log({\n            \"Loss/G_Total\": loss_G.item(),\n            \"Loss/G_GAN\": loss_GAN.item(),\n            \"Loss/G_Cycle\": loss_cycle.item(),\n            \"Loss/G_Identity\": loss_identity.item(),\n            \"Loss/D_Monet\": loss_D_Monet.item(),\n            \"Loss/D_Photo\": loss_D_Photo.item()\n        })\n        ",
    "\n",
    "        # -----------------------\n",
    "        #  Train Discriminator A\n",
    "        # -----------------------\n",
    "        optimizer_D_Monet.zero_grad()\n",
    "        loss_real = criterion_GAN(D_Monet(real_monet), torch.ones_like(D_Monet(real_monet)))\n",
    "        fake_monet_ = fake_monet_buffer.push_and_pop(fake_monet)\n",
    "        loss_fake = criterion_GAN(D_Monet(fake_monet_.detach()), torch.zeros_like(D_Monet(fake_monet_)))\n",
    "        loss_D_Monet = (loss_real + loss_fake) / 2\n",
    "        loss_D_Monet.backward()\n",
    "        optimizer_D_Monet.step()\n",
    "\n",
    "        # -----------------------\n",
    "        #  Train Discriminator B\n",
    "        # -----------------------\n",
    "        optimizer_D_Photo.zero_grad()\n",
    "        loss_real = criterion_GAN(D_Photo(real_photo), torch.ones_like(D_Photo(real_photo)))\n",
    "        fake_photo_ = fake_photo_buffer.push_and_pop(fake_photo)\n",
    "        loss_fake = criterion_GAN(D_Photo(fake_photo_.detach()), torch.zeros_like(D_Photo(fake_photo_)))\n",
    "        loss_D_Photo = (loss_real + loss_fake) / 2\n",
    "        loss_D_Photo.backward()\n",
    "        optimizer_D_Photo.step()\n",
    "    \n",
    "    # --- Update Learning Rate ---\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_Monet.step()\n",
    "    lr_scheduler_D_Photo.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} finished. Avg Generator Loss: {epoch_loss_G / len(train_loader):.4f}\")\n",
    "    \n",
    "    # --- Validation / Visualization ---\n",
    "    if (epoch + 1) % 1 == 0: # Visualize every epoch\n",
    "        G_Monet.eval()\n",
    "        G_Photo.eval()\n",
    "        with torch.no_grad():\n",
    "            fake_monet_vis = G_Monet(fixed_photo)\n",
    "            fake_photo_vis = G_Photo(fixed_monet)\n",
    "            show_generated_images(fixed_photo, fake_monet_vis, fixed_monet, fake_photo_vis)\n",
    "\n            # --- WandB Log Images ---\n            wandb.log({\n                \"Generated/Photo_to_Monet\": [wandb.Image(denormalize(fake_monet_vis[0]).cpu(), caption=\"Generated Monet\")],\n                \"Generated/Monet_to_Photo\": [wandb.Image(denormalize(fake_photo_vis[0]).cpu(), caption=\"Generated Photo\")]\n            })\n            ",
    "            \n",
    "    # --- Save Checkpoints ---\n",
    "    # Save EVERY epoch now\n",
    "    torch.save(G_Monet.state_dict(), os.path.join(CHECKPOINT_DIR, f'G_Monet_epoch_{epoch+1}.pth'))\n",
    "    torch.save(G_Photo.state_dict(), os.path.join(CHECKPOINT_DIR, f'G_Photo_epoch_{epoch+1}.pth'))\n",
    "    torch.save(D_Monet.state_dict(), os.path.join(CHECKPOINT_DIR, f'D_Monet_epoch_{epoch+1}.pth'))\n",
    "    torch.save(D_Photo.state_dict(), os.path.join(CHECKPOINT_DIR, f'D_Photo_epoch_{epoch+1}.pth'))\n",
    "    print(f\"Saved checkpoint for epoch {epoch+1} to {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing\n",
    "\n",
    "Finally, let's run the generator on the test set and see some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_Monet.eval()\n",
    "\n",
    "test_iter = iter(test_loader)\n",
    "\n",
    "# Show first 5 test images\n",
    "for i in range(5):\n",
    "    try:\n",
    "        batch = next(test_iter)\n",
    "        real_photo = batch['photo'].to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            fake_monet = G_Monet(real_photo)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(denormalize(real_photo[0]).permute(1, 2, 0).cpu().numpy())\n",
    "        plt.title(\"Real Photo (Test)\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(denormalize(fake_monet[0]).permute(1, 2, 0).cpu().numpy())\n",
    "        plt.title(\"Generated Monet (Test)\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n        # --- WandB Log Test Image ---\n        wandb.log({\n            \"Test/Generated_Monet\": [\n                wandb.Image(denormalize(fake_monet[0]).cpu(), caption=f\"Test Image {i+1}\")\n            ]\n        })\n        ",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- AUTOMATED REPORT GENERATION ---\n",
    "# This cell uses the WandB API to create a report dashboard automatically at the end of the run.\n",
    "\n",
    "try:\n",
    "    import wandb.apis.reports as wr\n",
    "    \n",
    "    # Configure Report\n",
    "    PROJECT = \"Monet_GAn\"\n",
    "    ENTITY = \"konstantine25b-free-university-of-tbilisi-\"\n",
    "    \n",
    "    report = wr.Report(\n",
    "        project=PROJECT,\n",
    "        entity=ENTITY,\n",
    "        title=\"CycleGAN Experiment Results\",\n",
    "        description=\"Automated report generated from experiment1.ipynb training run.\"\n",
    "    )\n",
    "    \n",
    "    # Define Report Structure\n",
    "    report.blocks = [\n",
    "        wr.H1(\"Experiment Overview\"),\n",
    "        wr.P(\"This report tracks the training progress of a CycleGAN model translating Photos to Monet paintings.\"),\n",
    "        wr.P(f\"Hyperparameters: Epochs={N_EPOCHS}, Batch Size={BATCH_SIZE}, LR={LR}\"),\n",
    "        \n",
    "        wr.H2(\"Training Losses\"),\n",
    "        wr.P(\"Tracking the Generator and Discriminator losses over time. Lower Generator loss generally indicates better convergence.\"),\n",
    "        wr.PanelGrid(\n",
    "            runsets=[wr.Runset(PROJECT, entity=ENTITY)],\n",
    "            panels=[\n",
    "                wr.LinePlot(x='Step', y=['Loss/G_Total'], title=\"Total Generator Loss\"),\n",
    "                wr.LinePlot(x='Step', y=['Loss/G_GAN', 'Loss/G_Cycle', 'Loss/G_Identity'], title=\"Generator Component Losses\"),\n",
    "                wr.LinePlot(x='Step', y=['Loss/D_Monet', 'Loss/D_Photo'], title=\"Discriminator Losses\")\n",
    "            ]\n",
    "        ),\n",
    "        \n",
    "        wr.H2(\"Generated Samples (Visual Validation)\"),\n",
    "        wr.P(\"Visualizing the transformation from Photo to Monet (and back) over epochs.\"),\n",
    "        wr.PanelGrid(\n",
    "            runsets=[wr.Runset(PROJECT, entity=ENTITY)],\n",
    "            panels=[\n",
    "                wr.MediaBrowserPanel(num_columns=2, media_keys=[\"Generated/Photo_to_Monet\"]),\n",
    "                wr.MediaBrowserPanel(num_columns=2, media_keys=[\"Generated/Monet_to_Photo\"])\n",
    "            ]\n",
    "        ),\n",
    "        \n",
    "        wr.H2(\"Test Set Results\"),\n",
    "        wr.P(\"Final evaluation on unseen test images.\"),\n",
    "        wr.PanelGrid(\n",
    "            runsets=[wr.Runset(PROJECT, entity=ENTITY)],\n",
    "            panels=[\n",
    "                wr.MediaBrowserPanel(num_columns=4, media_keys=[\"Test/Generated_Monet\"])\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Save Report\n",
    "    report.save()\n",
    "    print(f\"\u2705 WandB Report generated successfully! View it here: {report.url}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate report automatically: {e}\")\n",
    "    print(\"Note: Ensure you have access to the project and 'wandb' is up to date.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}