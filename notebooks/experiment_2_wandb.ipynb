{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 WandB: Logging & Evaluation\n",
    "\n",
    "This notebook loads the trained models from Experiment 2 (epochs 1-30), evaluates them to reconstruct loss curves and generate examples, and logs everything to a new Weights & Biases project.\n",
    "\n",
    "**Note:** This notebook is designed to run in Google Colab with access to the same Drive paths as `experiment2.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except ImportError:\n",
    "    print(\"Not running in Google Colab. Skipping Drive mount.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Matching paths from experiment2.ipynb\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    REPO_PATH = '/content/drive/MyDrive/Kaggle_GANS_I-m-Something-of-a-Painter-Myself_Competition'\n",
    "    CHECKPOINT_DIR = '/content/drive/MyDrive/MonetGAN_Checkpoints_Exp1'\n",
    "    \n",
    "    if os.path.exists(REPO_PATH):\n",
    "        os.chdir(REPO_PATH)\n",
    "        print(f\"Changed directory to {REPO_PATH}\")\n",
    "    else:\n",
    "        print(f\"WARNING: Repository path {REPO_PATH} not found. Please clone it first.\")\n",
    "else:\n",
    "    # Local fallback\n",
    "    REPO_PATH = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "    CHECKPOINT_DIR = os.path.join(REPO_PATH, 'checkpoints') # Or update if local checkpoints are elsewhere\n",
    "    if os.path.exists(REPO_PATH):\n",
    "        os.chdir(REPO_PATH)\n",
    "        print(f\"Changed directory to {REPO_PATH}\")\n",
    "\n",
    "# Ensure src is in path\n",
    "sys.path.append('src')\n",
    "\n",
    "MONET_PATH = 'data/monet_jpg'\n",
    "PHOTO_PATH = 'data/photo_jpg'\n",
    "\n",
    "print(f\"Checkpoint Directory: {CHECKPOINT_DIR}\")\n",
    "print(f\"Monet Data: {MONET_PATH}\")\n",
    "print(f\"Photo Data: {PHOTO_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb scipy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import linalg\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.models import inception_v3\n",
    "\n",
    "from models.generator.resnet_gan import ResNetGenerator\n",
    "from models.discriminator.patch_gan import PatchDiscriminator\n",
    "from utils.dataset import ImageDataset, get_transforms\n",
    "from utils.helpers import ReplayBuffer, weights_init_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB Config\n",
    "WANDB_PROJECT = \"Monet_GAN_Eval_Exp2\"\n",
    "WANDB_ENTITY = \"konstantine25b-free-university-of-tbilisi-\"\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "N_EPOCHS = 30\n",
    "LR = 0.0002\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified WandB Login\n",
    "# This will prompt you for an API key if not already logged in.\n",
    "# You can also set the WANDB_API_KEY environment variable.\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WandB Run\n",
    "wandb.init(\n",
    "    project=WANDB_PROJECT,\n",
    "    entity=WANDB_ENTITY,\n",
    "    config={\n",
    "        \"epochs\": N_EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LR,\n",
    "        \"architecture\": \"CycleGAN-ResNet\",\n",
    "        \"dataset\": \"Monet2Photo\",\n",
    "        \"experiment\": \"Experiment 2 Evaluation\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "monet_files = sorted(glob.glob(os.path.join(MONET_PATH, \"*.*\")))\n",
    "photo_files = sorted(glob.glob(os.path.join(PHOTO_PATH, \"*.*\")))\n",
    "\n",
    "print(f\"Total Monet images: {len(monet_files)}\")\n",
    "print(f\"Total Photo images: {len(photo_files)}\")\n",
    "\n",
    "# Shuffle files\n",
    "random.seed(42)\n",
    "random.shuffle(monet_files)\n",
    "random.shuffle(photo_files)\n",
    "\n",
    "def split_data(files, is_monet=False):\n",
    "    n_val = 1 if is_monet else 50\n",
    "    if is_monet:\n",
    "        val = files[:n_val]\n",
    "        train = files[n_val:]\n",
    "        test = []\n",
    "    else:\n",
    "        n_test = 30\n",
    "        val = files[:n_val]\n",
    "        test = files[n_val:n_val+n_test]\n",
    "        train = files[n_val+n_test:]\n",
    "    return train, val, test\n",
    "\n",
    "monet_train, monet_val, monet_test = split_data(monet_files, is_monet=True)\n",
    "photo_train, photo_val, photo_test = split_data(photo_files, is_monet=False)\n",
    "\n",
    "transforms_ = get_transforms()\n",
    "train_dataset = ImageDataset(monet_train, photo_train, transform=transforms_)\n",
    "val_dataset = ImageDataset(monet_val, photo_val, transform=transforms_)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Fixed samples for visualization\n",
    "val_batch = next(iter(val_loader))\n",
    "fixed_photo_val = val_batch['photo'].to(DEVICE)\n",
    "fixed_monet_val = val_batch['monet'].to(DEVICE)\n",
    "\n",
    "def denormalize(tensor):\n",
    "    return tensor * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "G_Monet = ResNetGenerator().to(DEVICE)\n",
    "G_Photo = ResNetGenerator().to(DEVICE)\n",
    "D_Monet = PatchDiscriminator().to(DEVICE)\n",
    "D_Photo = PatchDiscriminator().to(DEVICE)\n",
    "\n",
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MiFID Implementation ---\n",
    "# Based on Kaggle GANs Competitions (Monet, etc.)\n",
    "\n",
    "class InceptionV3(nn.Module):\n",
    "    \"\"\"Pretrained InceptionV3 network returning feature maps\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        inception = inception_v3(pretrained=True)\n",
    "        self.block1 = nn.Sequential(\n",
    "            inception.Conv2d_1a_3x3, inception.Conv2d_2a_3x3,\n",
    "            inception.Conv2d_2b_3x3, nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            inception.Conv2d_3b_1x1, inception.Conv2d_4a_3x3,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            inception.Mixed_5b, inception.Mixed_5c, inception.Mixed_5d,\n",
    "            inception.Mixed_6a, inception.Mixed_6b, inception.Mixed_6c,\n",
    "            inception.Mixed_6d, inception.Mixed_6e\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            inception.Mixed_7a, inception.Mixed_7b, inception.Mixed_7c,\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    \"\"\"Numpy implementation of the Frechet Distance.\"\"\"\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \"Training and test mean vectors have different lengths\"\n",
    "    assert sigma1.shape == sigma2.shape, \"Training and test covariances have different dimensions\"\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    # Product might be almost singular\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        print(\"fid calculation produces singular product; adding %s to diagonal of cov estimates\" % eps)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    # Numerical error might give slight imaginary component\n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError(\"Imaginary component {}\".format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean)\n",
    "\n",
    "def calculate_activation_statistics(images, model, batch_size=50, device='cuda'):\n",
    "    model.eval()\n",
    "    act = []\n",
    "    \n",
    "    if not isinstance(images, torch.Tensor):\n",
    "        # Assuming images is a list of tensors\n",
    "        pass\n",
    "    \n",
    "    dataloader = DataLoader(images, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Calculating Inception Features\"):\n",
    "            batch = batch.to(device)\n",
    "            # Resize to 299x299 for InceptionV3 if needed, or assume inputs are close\n",
    "            if batch.shape[-1] != 299:\n",
    "                 batch = F.interpolate(batch, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "            \n",
    "            pred = model(batch)\n",
    "            act.append(pred.cpu().numpy())\n",
    "\n",
    "    act = np.concatenate(act, axis=0)\n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    return mu, sigma, act\n",
    "\n",
    "def calculate_mifid(real_images_tensor, fake_images_tensor, model, device='cuda', eps=1e-15):\n",
    "    \"\"\"\n",
    "    Calculates MiFID between real and fake images.\n",
    "    real_images_tensor: Tensor of shape (N, C, H, W)\n",
    "    fake_images_tensor: Tensor of shape (N, C, H, W)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Calculate FID components\n",
    "    mu1, sigma1, act1 = calculate_activation_statistics(real_images_tensor, model, device=device)\n",
    "    mu2, sigma2, act2 = calculate_activation_statistics(fake_images_tensor, model, device=device)\n",
    "    \n",
    "    fid_value = calculate_frechet_distance(mu1, sigma1, mu2, sigma2)\n",
    "    \n",
    "    # 2. Calculate Memorization Distance (Cosine Distance)\n",
    "    # Formula: d_mem = 1/N * sum(min(d(f_gen, f_real)))\n",
    "    # We want cosine distance, so we normalize vectors first\n",
    "    \n",
    "    # Normalize features\n",
    "    act1_norm = act1 / (np.linalg.norm(act1, axis=1, keepdims=True) + eps)\n",
    "    act2_norm = act2 / (np.linalg.norm(act2, axis=1, keepdims=True) + eps)\n",
    "    \n",
    "    # Compute cosine similarity matrix (Fake x Real)\n",
    "    # act2 (Fake) dot act1.T (Real)\n",
    "    # Result is (N_fake, N_real) matrix of cosine similarities\n",
    "    # Distance = 1 - Similarity\n",
    "    # We want MINIMUM distance for each fake image to ANY real image\n",
    "    \n",
    "    # To save memory, compute in batches if needed, but for <10k images it might fit in RAM\n",
    "    # 7000 images * 2048 floats is manageable\n",
    "    \n",
    "    # Similarity\n",
    "    sim_matrix = np.dot(act2_norm, act1_norm.T)\n",
    "    \n",
    "    # Distance = 1 - Similarity\n",
    "    dist_matrix = 1.0 - sim_matrix\n",
    "    \n",
    "    # Find minimum distance for each generated image\n",
    "    min_distances = np.min(dist_matrix, axis=1)\n",
    "    \n",
    "    # Thresholding (per Kaggle spec, often 0.0 or small epsilon, but standard MiFID uses pure mean)\n",
    "    # Kaggle formula: if distance > epsilon, it's 1.0? \n",
    "    # Actually, the formula usually is just penalizing very small distances (memorization)\n",
    "    # Standard Kaggle implementation:\n",
    "    # memorization_distance = np.mean(min_distances)\n",
    "    # But usually applied as penalty: MiFID = FID + alpha / memorization_distance\n",
    "    # Wait, the user prompt says: \"The memorization distance is defined as the minimum cosine distance...\"\n",
    "    # And \"Finally, this memorization term is applied to the FID: FID = FID * (1 / (mem_dist + eps))\" or similar?\n",
    "    # Re-reading prompt: \"FID_m = FID + 1 / (N * d_mem)\"? No, let's look at the formula descriptions\n",
    "    # \"This distance is thresholded... assigned to 1.0 if distance exceeds pre-defined epsilon\"\n",
    "    # Let's assume a standard Kaggle implementation approach:\n",
    "    \n",
    "    # Thresholding logic from public kernels:\n",
    "    # distance_threshold = 0.00something\n",
    "    # But let's calculate the raw mean minimum distance first.\n",
    "    \n",
    "    memorization_dist = np.mean(min_distances)\n",
    "    \n",
    "    # MiFID formula from Kaggle usually:\n",
    "    # MiFID = FID + alpha / (memorization_dist + epsilon)\n",
    "    # Use alpha=1.0 for now if not specified\n",
    "    # NOTE: The user prompt doesn't give the EXACT final combination formula constant, \n",
    "    # but says \"memorization term is applied to the FID\"\n",
    "    # I will log FID, Memorization Distance, and a heuristic MiFID.\n",
    "    \n",
    "    mifid = fid_value * (1.0 / (memorization_dist + 1e-7)) # Heuristic based on description: smaller distance -> larger penalty -> larger MiFID (bad)\n",
    "    \n",
    "    return fid_value, memorization_dist, mifid\n",
    "\n",
    "# Initialize Inception Model\n",
    "inception_model = InceptionV3().to(DEVICE)\n",
    "inception_model.eval()\n",
    "print(\"InceptionV3 initialized for MiFID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-load Real Monet Images for MiFID (Standard for comparison)\n",
    "# We only need to compute statistics for real Monet images ONCE\n",
    "# Since we are generating Monets from Photos, we compare (Generated Monets) vs (Real Monets)\n",
    "\n",
    "print(\"Loading all Real Monet images for statistics...\")\n",
    "real_monet_tensor_list = []\n",
    "for f in tqdm(monet_files, desc=\"Loading Real Monets\"):\n",
    "    img = Image.open(f).convert('RGB')\n",
    "    img_t = transforms_(img)\n",
    "    real_monet_tensor_list.append(img_t)\n",
    "\n",
    "real_monet_stack = torch.stack(real_monet_tensor_list).to(DEVICE)\n",
    "print(f\"Real Monet Stack: {real_monet_stack.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "def evaluate_epoch(epoch, num_batches=20):\n",
    "    \"\"\"\n",
    "    Loads weights for the given epoch, runs a few batches to calculate loss,\n",
    "    and logs metrics and images to WandB.\n",
    "    \"\"\"\n",
    "    # 1. Load Weights\n",
    "    try:\n",
    "        G_Monet.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, f'G_Monet_epoch_{epoch}_2.pth'), map_location=DEVICE))\n",
    "        G_Photo.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, f'G_Photo_epoch_{epoch}_2.pth'), map_location=DEVICE))\n",
    "        D_Monet.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, f'D_Monet_epoch_{epoch}_2.pth'), map_location=DEVICE))\n",
    "        D_Photo.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, f'D_Photo_epoch_{epoch}_2.pth'), map_location=DEVICE))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Checkpoint for epoch {epoch} not found in {CHECKPOINT_DIR}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    # 2. Calculate Losses (using a subset of training data)\n",
    "    G_Monet.eval(); G_Photo.eval(); D_Monet.eval(); D_Photo.eval()\n",
    "    \n",
    "    total_loss_G = 0.0\n",
    "    total_loss_D_Monet = 0.0\n",
    "    total_loss_D_Photo = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "                \n",
    "            real_monet = batch['monet'].to(DEVICE)\n",
    "            real_photo = batch['photo'].to(DEVICE)\n",
    "            \n",
    "            # -- Generator Losses --\n",
    "            loss_id_A = criterion_identity(G_Monet(real_monet), real_monet)\n",
    "            loss_id_B = criterion_identity(G_Photo(real_photo), real_photo)\n",
    "            loss_identity = (loss_id_A + loss_id_B) / 2\n",
    "\n",
    "            fake_monet = G_Monet(real_photo)\n",
    "            loss_GAN_AB = criterion_GAN(D_Monet(fake_monet), torch.ones_like(D_Monet(fake_monet)))\n",
    "            fake_photo = G_Photo(real_monet)\n",
    "            loss_GAN_BA = criterion_GAN(D_Photo(fake_photo), torch.ones_like(D_Photo(fake_photo)))\n",
    "            loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
    "\n",
    "            rec_photo = G_Photo(fake_monet)\n",
    "            loss_cycle_A = criterion_cycle(rec_photo, real_photo)\n",
    "            rec_monet = G_Monet(fake_photo)\n",
    "            loss_cycle_B = criterion_cycle(rec_monet, real_monet)\n",
    "            loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
    "\n",
    "            loss_G = loss_GAN + (10.0 * loss_cycle) + (5.0 * loss_identity)\n",
    "            total_loss_G += loss_G.item()\n",
    "            \n",
    "            # -- Discriminator Losses --\n",
    "            loss_real_M = criterion_GAN(D_Monet(real_monet), torch.ones_like(D_Monet(real_monet)))\n",
    "            loss_fake_M = criterion_GAN(D_Monet(fake_monet), torch.zeros_like(D_Monet(fake_monet)))\n",
    "            total_loss_D_Monet += (loss_real_M + loss_fake_M).item() / 2\n",
    "            \n",
    "            loss_real_P = criterion_GAN(D_Photo(real_photo), torch.ones_like(D_Photo(real_photo)))\n",
    "            loss_fake_P = criterion_GAN(D_Photo(fake_photo), torch.zeros_like(D_Photo(fake_photo)))\n",
    "            total_loss_D_Photo += (loss_real_P + loss_fake_P).item() / 2\n",
    "\n",
    "    avg_loss_G = total_loss_G / num_batches\n",
    "    avg_loss_D_Monet = total_loss_D_Monet / num_batches\n",
    "    avg_loss_D_Photo = total_loss_D_Photo / num_batches\n",
    "    \n",
    "    # --- MiFID Calculation ---\n",
    "    # Generate a batch of fake Monets from Photos to compare against Real Monets\n",
    "    # We need a decent number of samples for FID, but doing full 7000 every epoch is slow.\n",
    "    # Let's do a smaller subset (e.g., 100 images) for epoch-wise tracking.\n",
    "    \n",
    "    print(\"Generating images for MiFID...\")\n",
    "    fake_monets_list = []\n",
    "    count = 0\n",
    "    num_mifid_samples = 100 # Adjust based on speed requirements\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        if count >= num_mifid_samples:\n",
    "            break\n",
    "        real_photo = batch['photo'].to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            fake = G_Monet(real_photo)\n",
    "            fake_monets_list.append(fake)\n",
    "            count += real_photo.size(0)\n",
    "            \n",
    "    fake_monet_stack = torch.cat(fake_monets_list, dim=0)[:num_mifid_samples]\n",
    "    \n",
    "    # We compare against a subset of real monets matching the size, or full set?\n",
    "    # Using full real set is better for stability.\n",
    "    fid, mem_dist, mifid = calculate_mifid(real_monet_stack, fake_monet_stack, inception_model, device=DEVICE)\n",
    "    \n",
    "    \n",
    "    # 3. Log Metrics\n",
    "    wandb.log({\n",
    "        \"Loss/G_Total\": avg_loss_G,\n",
    "        \"Loss/D_Monet\": avg_loss_D_Monet,\n",
    "        \"Loss/D_Photo\": avg_loss_D_Photo,\n",
    "        \"Metrics/FID\": fid,\n",
    "        \"Metrics/Memorization_Distance\": mem_dist,\n",
    "        \"Metrics/MiFID\": mifid,\n",
    "        \"epoch\": epoch\n",
    "    }, step=epoch)\n",
    "    \n",
    "    # 4. Generate and Log Images\n",
    "    # We only log 2 images (1 of each type) to avoid crashing WandB\n",
    "    with torch.no_grad():\n",
    "        # Use sliced input [0:1] to ensure we only generate and process 1 image\n",
    "        fake_monet_val_vis = G_Monet(fixed_photo_val[0:1])\n",
    "        fake_photo_val_vis = G_Photo(fixed_monet_val[0:1])\n",
    "        \n",
    "        wandb.log({\n",
    "            \"Generated/Val_Photo_to_Monet\": [wandb.Image(denormalize(fake_monet_val_vis[0]).cpu(), caption=f\"Epoch {epoch} Monet\")],\n",
    "            \"Generated/Val_Monet_to_Photo\": [wandb.Image(denormalize(fake_photo_val_vis[0]).cpu(), caption=f\"Epoch {epoch} Photo\")],\n",
    "        }, step=epoch)\n",
    "\n",
    "    # 5. Log Artifacts (Every 5th epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        artifact = wandb.Artifact(name=f\"model_epoch_{epoch}\", type=\"model\")\n",
    "        artifact.add_file(os.path.join(CHECKPOINT_DIR, f'G_Monet_epoch_{epoch}_2.pth'))\n",
    "        artifact.add_file(os.path.join(CHECKPOINT_DIR, f'G_Photo_epoch_{epoch}_2.pth'))\n",
    "        artifact.add_file(os.path.join(CHECKPOINT_DIR, f'D_Monet_epoch_{epoch}_2.pth'))\n",
    "        artifact.add_file(os.path.join(CHECKPOINT_DIR, f'D_Photo_epoch_{epoch}_2.pth'))\n",
    "        wandb.log_artifact(artifact)\n",
    "        print(f\"Logged artifact for epoch {epoch}\")\n",
    "\n",
    "    print(f\"Epoch {epoch}: G_Loss={avg_loss_G:.4f}, FID={fid:.4f}, MiFID={mifid:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the evaluation loop\n",
    "print(f\"Starting evaluation for {N_EPOCHS} epochs...\")\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    evaluate_epoch(epoch, num_batches=10)\n",
    "\n",
    "print(\"Done!\")\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
